{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154dcf4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load needed packages\n",
    "import logging\n",
    "import multiprocessing as mp\n",
    "import sys\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Handle warnings\n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from sklearn.utils._testing import ignore_warnings\n",
    "\n",
    "# Handle class imbalance\n",
    "from imblearn.pipeline import Pipeline as imbPipeline\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "from imblearn.under_sampling import (TomekLinks, \n",
    "                                     NeighbourhoodCleaningRule as NCR, \n",
    "                                     RandomUnderSampler)\n",
    "\n",
    "# Neural Network\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers.core import Dropout\n",
    "from keras import regularizers\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# ML\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "# Performance metrics\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold, cross_validate\n",
    "from sklearn.metrics import make_scorer\n",
    "from mlxtend.evaluate import lift_score\n",
    "\n",
    "# Assemble pipeline(s)\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.compose import ColumnTransformer, make_column_selector\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "from sklearn import set_config\n",
    "\n",
    "# Create own Classifier\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.utils.validation import check_X_y, check_array, check_is_fitted\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from scipy.sparse import csr_matrix, isspmatrix\n",
    "from GEVNN import MLP_AE\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58b7372",
   "metadata": {},
   "source": [
    "# 1. Initial configuration and loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28ebfd4",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Suppress annoying warnings\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "ignore_warnings(category=ConvergenceWarning)\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    os.environ[\"PYTHONWARNINGS\"] = ('ignore::UserWarning,ignore::RuntimeWarning')\n",
    "    \n",
    "# Take care of logging\n",
    "logging.basicConfig(\n",
    "    format='%(asctime)s:%(name)s:%(levelname)s - %(message)s',\n",
    "    level=logging.INFO,\n",
    "    handlers=[\n",
    "        logging.FileHandler(\"churn_benchmarking.log\"),\n",
    "        logging.StreamHandler()\n",
    "    ],\n",
    "    datefmt='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "# Determine number of cpus for parallel computing\n",
    "n_cpus = mp.cpu_count()\n",
    "logging.info(f\"{n_cpus} cpus available\")\n",
    "\n",
    "# Check if files for benchmarking already exist\n",
    "call = \"wget -qO- https://github.com/darinkist/customer_churn_benchmarking/raw/main/bnchmrk_datasets.tar.gz | tar -xvz\"\n",
    "\n",
    "if not os.path.isdir('00_data'):\n",
    "    logging.info(\"Directory 00_data not found - Downloading files\")\n",
    "    os.system(call)\n",
    "elif not os.listdir('00_data'):\n",
    "    logging.info(\"No files found - Downloading files\")\n",
    "    os.system(call)\n",
    "else:\n",
    "    logging.info(\"Files found\")\n",
    "\n",
    "# Visualize pipelines\n",
    "set_config(display=\"diagram\")\n",
    "\n",
    "# Load prepared (pre-cleaned) files for benchmarking\n",
    "file_paths = [f for f in glob.glob(\"00_data/*\") if f.endswith('_cleaned.csv')]\n",
    "file_names = [re.search('[ \\w-]+?(?=\\_cleaned.)',f)[0] for f in file_paths]\n",
    "\n",
    "dfs = [pd.read_csv(df, low_memory=False) for df in file_paths]\n",
    "data_sets = dict(zip(file_names, dfs))\n",
    "\n",
    "if not data_sets:\n",
    "    logging.error('No data sets have been loaded')\n",
    "    raise ValueError(\"No data sets have been loaded\")\n",
    "\n",
    "logging.info(f\"{len(data_sets)} data sets have been loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca9c134",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_sets.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13c6276",
   "metadata": {},
   "source": [
    "# 2. Defining sampling approaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70467300",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Store different sampling approaches\n",
    "sampl_app = dict()\n",
    "\n",
    "# No sampling\n",
    "sampl_app['no_sampling'] = ('no_sampling', None)\n",
    "\n",
    "# SMOTE\n",
    "sampl_app['o_SMOTE'] = ('smote', SMOTE())\n",
    "\n",
    "# ADASYN\n",
    "sampl_app['o_ADASYN'] = ('adasyn', ADASYN(sampling_strategy='not minority'))\n",
    "\n",
    "# TomekLinks\n",
    "sampl_app['u_TomekLinks'] = ('tomeklinks', TomekLinks())\n",
    "\n",
    "# NCR\n",
    "sampl_app['u_NCR'] = ('ncr', NCR())\n",
    "\n",
    "# SMOTE + RND\n",
    "sampl_app['h_SMOTE_RND'] = imbPipeline([('smote', SMOTE()),\n",
    "                                        ('rnd', RandomUnderSampler())])\n",
    "\n",
    "# SMOTE + TomekLinks\n",
    "sampl_app['h_SMOTE_Tomek'] = imbPipeline([('smote', SMOTE()),\n",
    "                                          ('tomeklinks', TomekLinks())])\n",
    "\n",
    "# SMOTE + NCR\n",
    "sampl_app['h_SMOTE_NCR'] = imbPipeline([('smote', SMOTE()),\n",
    "                                        ('ncr', \n",
    "                                         NCR(sampling_strategy='not majority'))]\n",
    "                                       )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b4805b",
   "metadata": {},
   "source": [
    "# 3. Define models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd6ef5f",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# https://github.com/lhagiimn/GEV-NN-A-deep-neural-network-architecture-for-class-imbalance-problem-in-binary-classification\n",
    "class GEV_NN_Classifier(BaseEstimator, ClassifierMixin):\n",
    "    \n",
    "    def __init__(self, epoch=50, batch_size=16, learning_rate=0.001, \n",
    "                 encoder=[32,16,8], decoder=[16,32], sofnn=[32], \n",
    "                 early_stopping=200, neurons=[32], activation='gev', \n",
    "                 reg_lambda=0.0001, loss_weight=0.25, rand=42, verbose_ae=0, \n",
    "                 verbose_mlp=0):\n",
    "    \n",
    "        self.epoch = epoch\n",
    "        self.batch_size = batch_size\n",
    "        self.learning_rate = learning_rate\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.sofnn = sofnn\n",
    "        self.early_stopping = early_stopping\n",
    "        self.neurons = neurons\n",
    "        self.activation = activation\n",
    "        self.reg_lambda = reg_lambda\n",
    "        self.loss_weight = loss_weight\n",
    "        self.rand = rand\n",
    "        self.verbose_ae = verbose_ae\n",
    "        self.verbose_mlp = verbose_mlp\n",
    "\n",
    "    def fit(self, X, y, **fit_params):\n",
    "        \n",
    "        if isspmatrix(X):\n",
    "            raise TypeError(\"Sparse input is not supported\")\n",
    "        \n",
    "        if not isinstance(X,(list,pd.core.series.Series,np.ndarray)):\n",
    "            raise ValueError(\"Not supported\")\n",
    "        \n",
    "        if fit_params:\n",
    "            if 'batch_size' in fit_params:\n",
    "                self.batch_size = fit_params['batch_size']\n",
    "                \n",
    "        \n",
    "        self.X_, self.y_ = check_X_y(X, y)\n",
    "        \n",
    "        self.n_features_in_ = X.shape[1]\n",
    "        self.classes_ = unique_labels(y)\n",
    "        self.is_fitted_ = True\n",
    "        \n",
    "        model = MLP_AE(trainX=self.X_, trainY=self.y_, epoch_number=self.epoch, \n",
    "                       batch_size=self.batch_size, \n",
    "                       learning_rate=self.learning_rate, encoder=self.encoder, \n",
    "                       decoder=self.decoder, sofnn=self.sofnn, \n",
    "                       early_stopping=self.early_stopping, neurons=self.neurons, \n",
    "                       activation=self.activation, reg_lambda=self.reg_lambda,\n",
    "                       loss_weight=self.loss_weight, rand=self.rand, \n",
    "                       verbose_ae=self.verbose_ae, verbose_mlp=self.verbose_mlp)\n",
    "        \n",
    "        self.model_ = model.MLP_AE()\n",
    "        return self\n",
    "    \n",
    "    def predict_proba(self, testX):\n",
    "\n",
    "        testX = check_array(testX)\n",
    "        check_is_fitted(self)\n",
    "        \n",
    "        _, pred_Y = self.model_.predict([testX, testX])\n",
    "        return pred_Y\n",
    "    \n",
    "    def decision_function(self, testX):\n",
    "        return self.predict_proba(testX)\n",
    "    \n",
    "    def predict(self, testX):\n",
    "\n",
    "        y_pred = self.predict_proba(testX)\n",
    "        y_pred = np.where(y_pred >= 0.5, 1, 0)\n",
    "\n",
    "        if len(self.classes_) == 1:\n",
    "            return np.squeeze(y_pred, 1)\n",
    "        else:\n",
    "            return np.squeeze(y_pred, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accd34e9",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Define different ML models\n",
    "\n",
    "# Feed Forward Neural Network\n",
    "# https://github.com/naomifridman/Neural-Network-Churn-Prediction/blob/master/FFNN_churn_predict_0_12174.ipynb\n",
    "def ffnn_mdl(meta):\n",
    "    \n",
    "    lsize=128\n",
    "    n_features_in_ = meta[\"n_features_in_\"]\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(lsize, input_dim=n_features_in_,activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(rate=0.25))\n",
    "    model.add(Dense(int(lsize/2), activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(rate=0.25))\n",
    "    model.add(Dense(int(lsize/4),kernel_regularizer=regularizers.l2(0.1), \n",
    "                    activation='relu'))\n",
    "    model.add(Dropout(rate=0.1))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    #metrics=[auroc] causes issues # adadelta was original\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', \n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Define callbacks\n",
    "reduce_lr = ReduceLROnPlateau(monitor='accuracy', factor=0.2,patience=1, \n",
    "                              min_lr=0.0001)\n",
    "reduce_val_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.4, \n",
    "                                  patience=1, min_lr=0.0001)\n",
    "es = EarlyStopping(monitor='loss', patience=3, verbose=1, mode='auto')\n",
    "\n",
    "callbacks_list = [es, reduce_lr, reduce_val_lr]\n",
    "\n",
    "\n",
    "ffnn = KerasClassifier(ffnn_mdl,\n",
    "                       epochs=50,\n",
    "                       batch_size=64,\n",
    "                       validation_split=0.2,\n",
    "                       callbacks=callbacks_list,\n",
    "                       verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83137ecf",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# GEV NN\n",
    "gev_nn = GEV_NN_Classifier()\n",
    "\n",
    "# Linear model (logistic regression)\n",
    "lr = LogisticRegression(solver='saga',\n",
    "                            warm_start=True,\n",
    "                            max_iter=100)\n",
    "\n",
    "# RandomForest\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "# XGB\n",
    "xgb = XGBClassifier(tree_method=\"hist\",\n",
    "                        verbosity=0,\n",
    "                        silent=True)\n",
    "\n",
    "# GaussianNB\n",
    "gnb = GaussianNB()\n",
    "\n",
    "# LR, XGB,RF\n",
    "lr_xgb_rf = VotingClassifier(estimators=[('lr', lr),\n",
    "                                         ('xgb', xgb),\n",
    "                                         ('rf', rf)], voting='soft')\n",
    "\n",
    "# LR, XGB,RF\n",
    "lr_xgb_rf = VotingClassifier(estimators=[('lr', lr),\n",
    "                                         ('xgb', xgb),\n",
    "                                         ('rf', rf)\n",
    "                                        ], voting='soft')\n",
    "\n",
    "# LR, XGB,RF, FFNN\n",
    "lr_xgb_rf_ffnn = VotingClassifier(estimators=[('lr', lr),\n",
    "                                         ('xgb', xgb),\n",
    "                                         ('rf', rf),\n",
    "                                         ('ffnn', ffnn)\n",
    "                                        ], voting='soft')\n",
    "\n",
    "# knn\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "# svc\n",
    "svc = SVC()\n",
    "\n",
    "# lgb\n",
    "lgb = LGBMClassifier()\n",
    "\n",
    "# Store them as tuples in a list\n",
    "models = [('lr', lr),\n",
    "          ('rf', rf),\n",
    "          ('xgb', xgb),\n",
    "          ('svc',svc),\n",
    "          ('gnb', gnb),\n",
    "          ('lgb', lgb),\n",
    "          ('knn', knn),\n",
    "          ('gev_nn', gev_nn),\n",
    "          ('ffnn', ffnn),\n",
    "          ('lr_xgb_rf', lr_xgb_rf),\n",
    "          ('lr_xgb_rf_ffnn', lr_xgb_rf_ffnn)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d98280",
   "metadata": {},
   "source": [
    "# 4. Initial pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b831e3d",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Initial pipeline\n",
    "ppl = imbPipeline([\n",
    "    ('transformation', ColumnTransformer([\n",
    "        ('num',make_pipeline(\n",
    "            SimpleImputer(strategy='mean'),\n",
    "            MinMaxScaler()),\n",
    "         make_column_selector(dtype_include='number')\n",
    "        ),\n",
    "        ('cat',make_pipeline(\n",
    "            SimpleImputer(strategy='most_frequent'),\n",
    "            OneHotEncoder(sparse=False, handle_unknown='ignore')),\n",
    "         make_column_selector(dtype_include='object')\n",
    "        )])\n",
    "    )\n",
    "])\n",
    "\n",
    "initial_steps = len(ppl.steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6002d335",
   "metadata": {},
   "outputs": [],
   "source": [
    "ppl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "854fd747",
   "metadata": {},
   "source": [
    "# 5. Scores to track and the right batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45efe666",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Scores to track\n",
    "scorer = {\n",
    "    'lift_score': make_scorer(lift_score),\n",
    "    'roc_auc':'roc_auc', \n",
    "    'f1_macro':'f1_macro', \n",
    "    'recall':'recall'\n",
    "}\n",
    "\n",
    "# To store the performance\n",
    "bnchmrk_results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52907346",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Determine batch size for NNs\n",
    "def helper_batch_size(X):\n",
    "    \n",
    "    if X.shape[0] < 500:\n",
    "        return 16\n",
    "    elif X.shape[0] < 1000:\n",
    "        return 32\n",
    "    elif X.shape[0] < 5000:\n",
    "        return 64\n",
    "    elif X.shape[0] < 10000:\n",
    "        return 128\n",
    "    elif X.shape[0] < 20000:\n",
    "        return 256\n",
    "    else:\n",
    "        return 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf7f770",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Cell for debugging/selective approaches\n",
    "# Should be set to False when appling the whole process\n",
    "DEBUG = False\n",
    "\n",
    "if DEBUG:\n",
    "    data_sets = {'ibm_hr': data_sets['ibm_hr']}\n",
    "    models = [('gev_nn', gev_nn)]\n",
    "    sampl_app = {'smote':('smote', SMOTE())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1cc7fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ppl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a097fa00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reset\n",
    "#ppl = ppl[:initial_steps]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d614f13",
   "metadata": {},
   "source": [
    "# 6. The benchmark loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99facfe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ds in data_sets.keys():\n",
    "    \n",
    "    logging.info(f\"= Starting benchmarking with {ds} data set =\")\n",
    "    \n",
    "    # Define X and y\n",
    "    X = data_sets[ds].drop(\"churn\", axis=1)\n",
    "    y = data_sets[ds][\"churn\"]\n",
    "    \n",
    "    model_results = {} # Store model performance\n",
    "    \n",
    "    for m in models:\n",
    "        \n",
    "        sampling_results = {} # Store sampling performance for respective model\n",
    "        for sa in sampl_app.keys():\n",
    "            \n",
    "            logging.info(f\"== Running {m[0]} with {sa} strategy ==\")\n",
    "            \n",
    "            # Extend initial pipeline by sampling approach and model\n",
    "            # Since some sampling approaches have multiple steps \n",
    "            # (e.g., SMOTE + RND) we have to append them via loop\n",
    "            if hasattr(sampl_app[sa], 'steps'):\n",
    "                for s in sampl_app[sa].steps:\n",
    "                    ppl.steps.append(s)\n",
    "            else:\n",
    "                ppl.steps.append(sampl_app[sa])\n",
    "            \n",
    "            # Add model to pipeline\n",
    "            ppl.steps.append(m)\n",
    "            \n",
    "            # Determine and set appropriate batch size for NN\n",
    "            if (m[0] == 'ffnn') or (m[0] == 'gev_nn'):\n",
    "                batch_size = helper_batch_size(X)\n",
    "                \n",
    "                if m[0] == 'ffnn':\n",
    "                    fit_params = {\"ffnn__batch_size\":batch_size}\n",
    "                if m[0] == 'gev_nn':\n",
    "                    fit_params = {\"gev_nn__batch_size\":batch_size}\n",
    "            else:\n",
    "                fit_params = None\n",
    "            \n",
    "            # Configure KFold and CV\n",
    "            rsf = RepeatedStratifiedKFold(n_repeats=5, random_state=42)\n",
    "            \n",
    "            scores = cross_validate(ppl, X, y, \n",
    "                                    cv=rsf, \n",
    "                                    scoring=scorer, \n",
    "                                    verbose=0, \n",
    "                                    n_jobs=1,\n",
    "                                    error_score='raise',\n",
    "                                    fit_params=fit_params,\n",
    "                                    return_estimator=False\n",
    "                                   )\n",
    "            \n",
    "            # Write results in dict\n",
    "            sampling_results[sa] = scores\n",
    "            \n",
    "            # After running CV we reset pipeline to initial state\n",
    "            # to be clean for next iteration\n",
    "            ppl = ppl[:initial_steps]\n",
    "        \n",
    "        # Write results in dict\n",
    "        model_results[m[0]] = sampling_results\n",
    "    \n",
    "    # Write results in dict\n",
    "    bnchmrk_results[ds] = model_results\n",
    "    \n",
    "    # After one data set has been benchmarked we persistent the results\n",
    "    file_to_write = open(f\"data_set_results_{ds}.pickle\", \"wb\")\n",
    "    pickle.dump(bnchmrk_results, file_to_write)\n",
    "    logging.info(f\"Results for {ds} have been written to pickle file\")\n",
    "\n",
    "# Done\n",
    "logging.info(\"Benchmarking finished\")         "
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
