{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15862c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99405c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths = [f for f in glob.glob(\"*\") if f.endswith('.pickle')]\n",
    "\n",
    "result = {}\n",
    "for pckl in file_paths:\n",
    "    result.update(pd.read_pickle(pckl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77acfdea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show different pickle files\n",
    "file_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0638b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data set in a shape that we get the overall performance per sampling approach and model\n",
    "{\n",
    "    'sampling approach sa': {\n",
    "        'model mo': {\n",
    "            'metric me': []\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5f72ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since all dicts have the same structure I just take the first one\n",
    "models = result['ibm_hr'].keys()\n",
    "sampling_approaches = result['ibm_hr']['lr'].keys()\n",
    "shaped_results = dict.fromkeys(sampling_approaches, dict.fromkeys(models,[]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786c68ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check - To check if transformation works fine\n",
    "sanity_check = np.mean(\n",
    "    result['ibm_hr']['lr']['no_sampling']['test_roc_auc'].tolist() +\n",
    "    result['ccp']['lr']['no_sampling']['test_roc_auc'].tolist() +\n",
    "    result['prt_bank']['lr']['no_sampling']['test_roc_auc'].tolist()\n",
    ")\n",
    "sanity_check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24fcaca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_conv(l):\n",
    "    # if l is not a list (assuming its an array) then convert it\n",
    "    return l.tolist() if type(l) is not list else l\n",
    "\n",
    "def metric_merger(d1, d2):\n",
    "    agg = dict.fromkeys(d1.keys(),[])\n",
    "    \n",
    "    for k,v in d1.items():\n",
    "        agg[k] = agg[k] + list_conv(d1[k]) + list_conv(d2[k])\n",
    "    return agg\n",
    "\n",
    "# To store the restructured dict\n",
    "prf = {}\n",
    "\n",
    "for ds in result.keys():\n",
    "    for m in result[ds].keys():\n",
    "        for sa in result[ds][m].keys():\n",
    "            \n",
    "            if sa in prf:\n",
    "                if m in prf[sa]:\n",
    "                    prf[sa][m]=metric_merger(prf[sa][m],result[ds][m][sa])\n",
    "                else:\n",
    "                    prf[sa][m] = result[ds][m][sa]\n",
    "            else:\n",
    "                prf[sa] = {}\n",
    "                prf[sa][m] = result[ds][m][sa]          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8728d6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same as sanity check above\n",
    "np.mean(prf['no_sampling']['lr']['test_roc_auc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c47bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_comparision_chart(values, labels, sampling_approach, \n",
    "                           ylabel='ROC AUC', nrows=1, ncols=1, n=1):\n",
    "    \n",
    "    # Create axes object\n",
    "    ax = plt.subplot(nrows, ncols, n + 1)\n",
    "    bp = plt.boxplot(values, labels=[str(m) for m in labels], \n",
    "                     showmeans=True, vert=False)\n",
    "    \n",
    "    # Annotate boxplot with mean values\n",
    "    for line in bp['means']:\n",
    "        xd = line.get_xdata()[0]\n",
    "        yd = line.get_ydata()[0]\n",
    "        coo = line.get_xydata()\n",
    "        plt.annotate('%.3f' % xd, \n",
    "                     [xd, yd-0.05],\n",
    "                     horizontalalignment='center',\n",
    "                     fontsize=8,\n",
    "                     weight='bold'\n",
    "                    )\n",
    "    ax.set_title(f\"{sampling_approach}\")\n",
    "    return ax\n",
    "\n",
    "\n",
    "ncols = 2\n",
    "nrows = len(prf.keys()) // ncols + (len(prf.keys()) % ncols > 0)\n",
    "\n",
    "fig = plt.figure(figsize=(15,15), dpi=200)\n",
    "\n",
    "for n, sampling_approach in enumerate(prf.keys()):\n",
    "    \n",
    "    # Store values and labels for the axes\n",
    "    values = []\n",
    "    labels = []\n",
    "    \n",
    "    # Get model's performance for given sampling approach\n",
    "    for m in models:\n",
    "        values.append(prf[sampling_approach][m]['test_roc_auc'])\n",
    "        labels.append(m)\n",
    "    \n",
    "    # Create axes object\n",
    "    plot_comparision_chart(values, labels, sampling_approach, ylabel=\"ROC AUC\", \n",
    "                           nrows=nrows, ncols=ncols,n=n)\n",
    "\n",
    "fig.suptitle(\"Mean ROC AUC of different sampling approaches (limited on IBM HR data set only)\", fontsize=18, y=1)\n",
    "plt.tight_layout()\n",
    "plt.show()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7970ba2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
